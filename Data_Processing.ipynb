{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Learning.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNN4hYGd9pfOvLhTA8ObneS"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install all requirements for the code\n",
        "!pip install opendatasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMvKWb0j1FrS",
        "outputId": "0e8eb932-8370-47e8-b09d-b48a97d04a89"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.20-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from opendatasets) (7.1.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from opendatasets) (4.62.3)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (from opendatasets) (1.5.12)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (1.15.0)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (6.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2.23.0)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2021.10.8)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->opendatasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->opendatasets) (3.0.4)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndQjHvgXz6Pw",
        "outputId": "ff4d0fb8-6c2a-49b1-8bf5-b6ffeed58ad0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: elijahtamarchenko\n",
            "Your Kaggle Key: ··········\n",
            "Downloading arxiv.zip to ./arxiv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.02G/1.02G [00:07<00:00, 146MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Download the dataset from Kaggle\n",
        "import opendatasets as od\n",
        "od.download(\"https://www.kaggle.com/Cornell-University/arxiv?select=arxiv-metadata-oai-snapshot.json\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the dataset into notebook\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Set initial variables\n",
        "data_file = '../content/arxiv/arxiv-metadata-oai-snapshot.json'\n",
        "start_year, end_year = 2000, 2002\n",
        "\n",
        "# Retrieve the data from the file\n",
        "def get_metadata():\n",
        "    with open(data_file, 'r') as f:\n",
        "        for line in f:\n",
        "            yield line\n",
        "# Return a pandas dataframe with the data\n",
        "def get_data():\n",
        "  metadata = get_metadata()\n",
        "  for paper in metadata:\n",
        "      paper_dict = json.loads(paper)\n",
        "  \n",
        "  data = [[] for i in range(6)]\n",
        "\n",
        "  metadata = get_metadata()\n",
        "  # Add the appropriate data to the array\n",
        "  for paper in metadata:\n",
        "      paper_dict = json.loads(paper)\n",
        "      ref = paper_dict.get('journal-ref')\n",
        "      try:\n",
        "          year = int(ref[-4:]) \n",
        "          if start_year <= year <= end_year:\n",
        "              data[0].append(year)\n",
        "              data[1].append(paper_dict.get('id'))\n",
        "              data[2].append(paper_dict.get('authors_parsed'))\n",
        "              data[3].append(paper_dict.get('authors'))\n",
        "              data[4].append(paper_dict.get('title'))\n",
        "              data[5].append(paper_dict.get('abstract'))\n",
        "      except:\n",
        "          pass \n",
        "          \n",
        "  # Creare the dataframe\n",
        "  papers = pd.DataFrame({\n",
        "      'id' : data[1],\n",
        "      'title': data[4],\n",
        "      'authors': data[3],\n",
        "      'authors parsed': data[2],\n",
        "      'abstract': data[5],\n",
        "      'year': data[0]\n",
        "  })\n",
        "  papers.head()\n",
        "  return papers\n"
      ],
      "metadata": {
        "id": "bOf2Xb2G2XBL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the dataset into a Pandas Dataframe\n",
        "papers = get_data()"
      ],
      "metadata": {
        "id": "-9OK0eK87A2f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}