{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP9xydMREOcEdJt31NPGQV1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/etchenko/Deep_Learning_Project/blob/main/Data_Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install all requirements for the code\n",
        "!pip install opendatasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMvKWb0j1FrS",
        "outputId": "3854ddf4-e193-4ca2-927d-006f529c7d20"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opendatasets\n",
            "  Downloading opendatasets-0.1.20-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from opendatasets) (4.63.0)\n",
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.7/dist-packages (from opendatasets) (1.5.12)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from opendatasets) (7.1.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2021.10.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (2.8.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (1.24.3)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (6.1.1)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.7/dist-packages (from kaggle->opendatasets) (1.15.0)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle->opendatasets) (1.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->opendatasets) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->kaggle->opendatasets) (3.0.4)\n",
            "Installing collected packages: opendatasets\n",
            "Successfully installed opendatasets-0.1.20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndQjHvgXz6Pw",
        "outputId": "51c21464-60ea-4614-fe85-922f8dc50a77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
            "Your Kaggle username: elijahtamarchenko\n",
            "Your Kaggle Key: ··········\n",
            "Downloading janatahack-independence-day-2020-ml-hackathon.zip to ./janatahack-independence-day-2020-ml-hackathon\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11.4M/11.4M [00:00<00:00, 105MB/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Download the dataset from Kaggle\n",
        "import opendatasets as od\n",
        "#od.download(\"https://www.kaggle.com/Cornell-University/arxiv?select=arxiv-metadata-oai-snapshot.json\")\n",
        "od.download(\"https://www.kaggle.com/vetrirah/janatahack-independence-day-2020-ml-hackathon?select=train.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the dataset into notebook\n",
        "import json\n",
        "import pandas as pd\n",
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "# Set initial variables\n",
        "data_file = '/arxiv/arxiv-metadata-oai-snapshot.json'\n",
        "data2 = '/janatahack-independence-day-2020-ml-hackathon/train.csv'\n",
        "start_year, end_year = 2000, 2002\n",
        "\n",
        "# Retrieve the data from the file\n",
        "def get_metadata():\n",
        "    with open(data_file, 'r') as f:\n",
        "        for line in f:\n",
        "            yield line\n",
        "# Return a pandas dataframe with the data\n",
        "def get_data():\n",
        "  metadata = get_metadata()\n",
        "  for paper in metadata:\n",
        "      paper_dict = json.loads(paper)\n",
        "  \n",
        "  data = [[] for i in range(7)]\n",
        "\n",
        "  metadata = get_metadata()\n",
        "  # Add the appropriate data to the array\n",
        "  for paper in metadata:\n",
        "      paper_dict = json.loads(paper)\n",
        "      ref = paper_dict.get('journal-ref')\n",
        "      try:\n",
        "          year = int(ref[-4:]) \n",
        "          if start_year <= year <= end_year:\n",
        "              data[0].append(year)\n",
        "              data[1].append(paper_dict.get('id'))\n",
        "              data[2].append(paper_dict.get('authors_parsed'))\n",
        "              data[3].append(paper_dict.get('authors'))\n",
        "              data[4].append(paper_dict.get('title'))\n",
        "              data[5].append(paper_dict.get('abstract'))\n",
        "              data[6].append(paper_dict.get('categories'))\n",
        "      except:\n",
        "          pass \n",
        "          \n",
        "  # Creare the dataframe\n",
        "  #papers = pd.DataFrame({\n",
        "      #'id' : data[1],\n",
        "      #'title': data[4],\n",
        "      #'authors': data[3],\n",
        "      #'authors parsed': data[2],\n",
        "      #'abstract': data[5],\n",
        "      #'year': data[0]\n",
        "      #'categories': data[6]\n",
        "  #})\n",
        "  #papers.head()\n",
        "\n",
        "  x = np.array(data[5])\n",
        "  y = np.array(data[6])\n",
        "  return x, y\n",
        "\n",
        "def get_data_2():\n",
        "  with open(data2, 'r') as file:\n",
        "    csvreader = csv.reader(file)\n",
        "    header = []\n",
        "    header = next(csvreader)\n",
        "    rows = []\n",
        "    for row in csvreader:\n",
        "      rows.append(row)\n",
        "    x = np.array(rows[:,2])\n",
        "    y = np.array(rows[:,3:])\n",
        "  return x, y\n",
        "\n"
      ],
      "metadata": {
        "id": "bOf2Xb2G2XBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "# Download the dataset into a Pandas Dataframe\n",
        "x, y = get_data()\n",
        "x2, y2 = get_data_2()\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y)\n",
        "x2_train, x_test, y_train, y_test = train_test_split(x2,y2)"
      ],
      "metadata": {
        "id": "-9OK0eK87A2f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}